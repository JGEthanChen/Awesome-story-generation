# Awesome-Story-Generation

## Paper

- **Storyline** : Plan-And-Write: Towards Better Automatic Storytelling  AAAI, 2019  [[paper]](https://arxiv.org/pdf/1811.05701.pdf)   [[code]](https://bitbucket.org/VioletPeng/language-model)
- **Propmt for hierarchical generation**: Hierarchical Neural Story Generation   ACL, 2018 [[paper]](https://arxiv.org/pdf/1805.04833.pdf)   [[code]](https://github.com/kevalnagda/StoryGeneration)
- **New paper**: Guiding Neural Story Generation with Reader Models  arXiv  [[paper]](https://arxiv.org/pdf/2112.08596.pdf)  
- **New paper with controllable gpt**：Goal-Directed Story Generation: Augmenting Generative Language Models with Reinforcement Learning
- **Using control factors**: Towards Controllable Story Generation
- **By sentence rewriting and reordering**: Towards Document-Level Paraphrase Generation with Sentence Rewriting and Reordering
- **By event representation**: Event Representations for Automated Story Generation with Deep Neural Nets
- **Dialogue generation concerning character relations**: Telling Stories through Multi-User Dialogue by Modeling Character Relations
- **By plot**: Story Realization: Expanding Plot Events into Sentences
- NEUROLOGIC A* Fesque Decoding: Constrained Text Generation with Lookahead Heuristics arXiv [[paper]](https://arxiv.org/pdf/2112.08726v1.pdf)
- Plans and Planning in Narrative Generation: A Review of  Plan-Based Approaches to the Generation of Story, Discourse and Interactivity in Narratives
- **An old review**: From Linear Story Generation to Branching Story Graphs
- **Story gan**: StoryGAN: A Sequential Conditional GAN for Story Visualization  CVPR, 2019  [[paper]](https://arxiv.org/pdf/1812.02784v2.pdf)   [[code]](https://github.com/yitong91/StoryGAN)

#### Some about extraction

- **An up-to-date Review of  Relation Extraction**: More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction
- **Information extraction**: Neural Information Extraction From Natural Language Text
- **Event extraction**: Joint Extraction of Events and Entities within a Document Context

####  Microsoft Textworld

- **Nearly review**: Modeling Worlds in Text
- **Introduction**: TextWorld: A Learning Environment for Text-based Games
- State Prediction in TextWorld with a Predicate-Logic Pointer Network Architecture
- Generating Interactive Worlds with Text
- https://github.com/microsoft/TextWorld

#### FAIR LIGHT

- Learning to Speak and Act in a Fantasy Text Adventure Game
- https://github.com/facebookresearch/ParlAI/tree/main/projects/light
- **Some other awesome projects in ParlAI**: https://github.com/facebookresearch/ParlAI

## Dataset

- [**ROC Stories**](https://cs.rochester.edu/nlp/rocstories/):   is a collection of commonsense short stories. The corpus consists of 100,000 five-sentence stories. Each story logically follows everyday topics created by Amazon Mechanical Turk workers. These stories contain a variety of commonsense causal and temporal relations between everyday events. Writers also develop an additional 3,742 Story Cloze Test stories which contain a four-sentence-long body and two candidate endings. The endings were collected by asking Mechanical Turk workers to write both a right ending and a wrong ending after eliminating original endings of given short stories. Both endings were required to make logical sense and include at least one character from the main story line. The published ROCStories dataset is constructed with ROCStories as a training set that includes 98,162 stories that exclude candidate wrong endings, an evaluation set, and a test set, which have the same structure (1 body + 2 candidate endings) and a size of 1,871. This corpus is unique in two ways: 

  ​		(1) it captures a rich set of causal and temporal commonsense relations between daily events；

  ​		(2) it is a high quality collection of everyday life stories that can also be used for story generation.

- [**CommonGen**](https://inklab.usc.edu/CommonGen/):  CommonGen is constructed through a combination of crowdsourced and existing caption corpora, consists of 79k commonsense descriptions over 35k unique concept-sets.



